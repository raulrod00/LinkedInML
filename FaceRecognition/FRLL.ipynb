{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4836cb87-843b-4d13-b6ac-9d5fa3a16077",
   "metadata": {},
   "source": [
    "# Face Recognition LinkedIn Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311b507-5dec-4d6e-a647-3235724875f5",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee77d7aa-9608-4259-b803-c76fea9e9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5528f378-93f2-40dc-b15d-32320320fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"./03/people.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff14c32c-915e-4a16-b0a7-f559c2b03c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the faces in the image\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5cf1095-3d45-4ea0-a741-08f436081965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 6 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "number_of_faces = len(face_locations)\n",
    "print(\"I found {} face(s) in this photograph.\".format(number_of_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6a6c73-3eed-4492-8264-c721d12ccf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A face is located at pixel location Top: 163, Left: 497, Bottom: 271, Right: 605\n",
      "A face is located at pixel location Top: 186, Left: 275, Bottom: 275, Right: 364\n",
      "A face is located at pixel location Top: 211, Left: 67, Bottom: 319, Right: 175\n",
      "A face is located at pixel location Top: 295, Left: 653, Bottom: 402, Right: 760\n",
      "A face is located at pixel location Top: 271, Left: 366, Bottom: 378, Right: 474\n",
      "A face is located at pixel location Top: 152, Left: 724, Bottom: 259, Right: 832\n"
     ]
    }
   ],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it and display it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image. Each face is a list of co-ordinates in (top, right, bottom, left) order.\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # Let's draw a box around the face\n",
    "    draw = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c5ecdc-0e88-42b3-a4eb-0a58fdd72ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image on screen\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926c637-793b-4b72-b60d-af309197257c",
   "metadata": {},
   "source": [
    "## Landmark Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cc13b4-fc7c-4a13-99e6-9fe3b1988e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9562f811-c13d-458c-89e2-d9b030a7c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"./04/people.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decb2b1a-0157-471f-977c-c39c8592ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3ac054-b371-4156-95c6-e0fd3fdb304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 6 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "number_of_faces = len(face_landmarks_list)\n",
    "print(\"I found {} face(s) in this photograph.\".format(number_of_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d94a26-e63c-4576-a304-be821b45ecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chin in this face has the following points: [(497, 193), (498, 206), (499, 219), (500, 232), (504, 244), (512, 255), (521, 264), (532, 271), (544, 274), (557, 272), (569, 266), (579, 258), (588, 247), (593, 234), (596, 221), (597, 208), (598, 194)]\n",
      "The left_eyebrow in this face has the following points: [(508, 186), (514, 182), (520, 179), (528, 179), (536, 181)]\n",
      "The right_eyebrow in this face has the following points: [(558, 180), (566, 179), (574, 179), (582, 180), (588, 186)]\n",
      "The nose_bridge in this face has the following points: [(547, 191), (546, 200), (546, 208), (545, 217)]\n",
      "The nose_tip in this face has the following points: [(536, 221), (541, 223), (546, 225), (551, 223), (556, 221)]\n",
      "The left_eye in this face has the following points: [(517, 193), (522, 190), (528, 190), (533, 193), (527, 194), (522, 194)]\n",
      "The right_eye in this face has the following points: [(562, 193), (567, 190), (573, 190), (578, 193), (573, 194), (567, 194)]\n",
      "The top_lip in this face has the following points: [(526, 236), (533, 234), (540, 233), (546, 235), (551, 234), (558, 235), (565, 237), (563, 237), (551, 236), (545, 236), (540, 235), (528, 236)]\n",
      "The bottom_lip in this face has the following points: [(565, 237), (558, 243), (550, 246), (545, 246), (539, 245), (532, 242), (526, 236), (528, 236), (539, 240), (545, 241), (551, 241), (563, 237)]\n",
      "The chin in this face has the following points: [(275, 203), (276, 214), (277, 225), (278, 237), (282, 247), (288, 257), (296, 265), (304, 272), (315, 275), (326, 274), (335, 268), (342, 260), (347, 250), (351, 241), (354, 230), (355, 219), (356, 208)]\n",
      "The left_eyebrow in this face has the following points: [(284, 196), (290, 192), (297, 193), (303, 195), (310, 199)]\n",
      "The right_eyebrow in this face has the following points: [(327, 199), (334, 196), (341, 194), (348, 195), (352, 200)]\n",
      "The nose_bridge in this face has the following points: [(319, 207), (318, 215), (318, 223), (318, 230)]\n",
      "The nose_tip in this face has the following points: [(307, 232), (312, 234), (318, 236), (323, 235), (328, 234)]\n",
      "The left_eye in this face has the following points: [(291, 206), (296, 203), (302, 204), (306, 209), (301, 209), (295, 209)]\n",
      "The right_eye in this face has the following points: [(330, 210), (335, 207), (341, 206), (345, 209), (341, 211), (335, 211)]\n",
      "The top_lip in this face has the following points: [(296, 242), (304, 240), (311, 240), (317, 242), (323, 241), (330, 242), (336, 245), (334, 245), (322, 245), (317, 245), (311, 244), (298, 243)]\n",
      "The bottom_lip in this face has the following points: [(336, 245), (330, 255), (322, 259), (316, 259), (310, 258), (302, 253), (296, 242), (298, 243), (311, 252), (317, 253), (322, 252), (334, 245)]\n",
      "The chin in this face has the following points: [(65, 230), (65, 244), (65, 258), (65, 272), (68, 286), (74, 298), (83, 309), (94, 318), (107, 323), (122, 323), (136, 318), (149, 310), (159, 299), (166, 286), (170, 271), (173, 257), (175, 242)]\n",
      "The left_eyebrow in this face has the following points: [(76, 223), (84, 218), (94, 218), (104, 219), (113, 224)]\n",
      "The right_eyebrow in this face has the following points: [(129, 226), (139, 224), (149, 224), (159, 227), (166, 234)]\n",
      "The nose_bridge in this face has the following points: [(120, 235), (119, 245), (117, 254), (116, 265)]\n",
      "The nose_tip in this face has the following points: [(103, 268), (109, 270), (115, 273), (122, 272), (129, 271)]\n",
      "The left_eye in this face has the following points: [(88, 231), (94, 229), (100, 230), (105, 235), (99, 235), (93, 233)]\n",
      "The right_eye in this face has the following points: [(135, 239), (141, 235), (147, 236), (153, 240), (147, 240), (140, 240)]\n",
      "The top_lip in this face has the following points: [(89, 278), (98, 279), (107, 281), (114, 283), (122, 283), (131, 284), (140, 285), (137, 286), (121, 285), (114, 285), (106, 283), (92, 280)]\n",
      "The bottom_lip in this face has the following points: [(140, 285), (130, 297), (119, 301), (112, 301), (104, 299), (95, 292), (89, 278), (92, 280), (105, 291), (113, 294), (120, 294), (137, 286)]\n",
      "The chin in this face has the following points: [(655, 327), (654, 341), (654, 355), (657, 369), (664, 381), (674, 393), (684, 403), (696, 411), (710, 414), (723, 411), (735, 403), (746, 393), (754, 381), (760, 367), (763, 353), (764, 338), (763, 325)]\n",
      "The left_eyebrow in this face has the following points: [(665, 311), (672, 305), (681, 304), (690, 307), (697, 311)]\n",
      "The right_eyebrow in this face has the following points: [(718, 310), (727, 306), (736, 303), (746, 305), (753, 311)]\n",
      "The nose_bridge in this face has the following points: [(708, 321), (709, 331), (709, 342), (709, 352)]\n",
      "The nose_tip in this face has the following points: [(695, 355), (702, 357), (709, 360), (716, 358), (722, 355)]\n",
      "The left_eye in this face has the following points: [(673, 320), (680, 318), (687, 319), (693, 324), (686, 323), (680, 322)]\n",
      "The right_eye in this face has the following points: [(723, 323), (729, 318), (736, 317), (742, 319), (737, 321), (730, 322)]\n",
      "The top_lip in this face has the following points: [(680, 367), (689, 364), (699, 364), (708, 366), (716, 364), (727, 364), (737, 366), (734, 367), (716, 368), (708, 369), (699, 368), (682, 367)]\n",
      "The bottom_lip in this face has the following points: [(737, 366), (728, 379), (717, 385), (708, 386), (699, 385), (689, 379), (680, 367), (682, 367), (699, 379), (708, 379), (717, 378), (734, 367)]\n",
      "The chin in this face has the following points: [(362, 296), (362, 310), (364, 324), (366, 336), (371, 349), (379, 361), (389, 371), (400, 379), (412, 382), (424, 380), (435, 371), (444, 361), (452, 349), (456, 337), (458, 324), (460, 312), (461, 300)]\n",
      "The left_eyebrow in this face has the following points: [(376, 292), (383, 288), (392, 286), (401, 287), (409, 292)]\n",
      "The right_eyebrow in this face has the following points: [(424, 294), (432, 292), (440, 291), (448, 293), (454, 297)]\n",
      "The nose_bridge in this face has the following points: [(417, 299), (417, 308), (417, 318), (417, 328)]\n",
      "The nose_tip in this face has the following points: [(406, 330), (411, 333), (417, 335), (422, 333), (426, 331)]\n",
      "The left_eye in this face has the following points: [(388, 298), (393, 295), (400, 294), (405, 299), (399, 299), (393, 299)]\n",
      "The right_eye in this face has the following points: [(426, 300), (432, 296), (438, 296), (444, 299), (438, 301), (432, 300)]\n",
      "The top_lip in this face has the following points: [(388, 339), (398, 339), (407, 340), (414, 342), (420, 340), (428, 340), (437, 341), (433, 342), (421, 343), (414, 344), (407, 343), (391, 340)]\n",
      "The bottom_lip in this face has the following points: [(437, 341), (428, 352), (420, 357), (414, 357), (406, 356), (396, 351), (388, 339), (391, 340), (406, 351), (414, 352), (420, 351), (433, 342)]\n",
      "The chin in this face has the following points: [(744, 188), (742, 199), (741, 210), (741, 222), (745, 234), (751, 244), (759, 254), (766, 263), (778, 266), (791, 265), (802, 259), (814, 251), (823, 242), (830, 230), (833, 217), (833, 204), (834, 191)]\n",
      "The left_eyebrow in this face has the following points: [(747, 176), (750, 170), (757, 167), (765, 168), (772, 171)]\n",
      "The right_eyebrow in this face has the following points: [(785, 171), (795, 169), (804, 169), (813, 173), (819, 179)]\n",
      "The nose_bridge in this face has the following points: [(778, 182), (777, 189), (776, 195), (775, 203)]\n",
      "The nose_tip in this face has the following points: [(764, 209), (770, 211), (776, 213), (783, 211), (789, 210)]\n",
      "The left_eye in this face has the following points: [(753, 183), (758, 180), (764, 180), (769, 184), (764, 185), (758, 185)]\n",
      "The right_eye in this face has the following points: [(792, 185), (798, 181), (804, 181), (809, 185), (804, 187), (798, 187)]\n",
      "The top_lip in this face has the following points: [(755, 226), (761, 221), (770, 220), (776, 222), (783, 221), (793, 223), (802, 228), (799, 228), (783, 224), (776, 225), (769, 224), (758, 226)]\n",
      "The bottom_lip in this face has the following points: [(802, 228), (793, 238), (783, 242), (775, 242), (769, 241), (761, 236), (755, 226), (758, 226), (769, 235), (776, 236), (783, 236), (799, 228)]\n"
     ]
    }
   ],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it and display it\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "\n",
    "# Create a PIL drawing object to be able to draw lines later\n",
    "draw = PIL.ImageDraw.Draw(pil_image)\n",
    "\n",
    "# Loop over each face\n",
    "for face_landmarks in face_landmarks_list:\n",
    "\n",
    "    # Loop over each facial feature (eye, nose, mouth, lips, etc)\n",
    "    for name, list_of_points in face_landmarks.items():\n",
    "\n",
    "        # Print the location of each facial feature in this image\n",
    "        print(\"The {} in this face has the following points: {}\".format(name, list_of_points))\n",
    "\n",
    "        # Let's trace out each facial feature in the image with a line!\n",
    "        draw.line(list_of_points, fill=\"red\", width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f90f4c90-224f-4570-82b3-de35aa1c5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79765046-d043-40b8-9abf-ca1741eb2571",
   "metadata": {},
   "source": [
    "## Face Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430cc3b4-ae1a-4bfa-8071-d2537d66c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b885344b-3cd3-4b86-a9f6-ad5a018c17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg files into numpy arrays\n",
    "image = face_recognition.load_image_file(\"./05/person.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13639b4d-0dcb-4762-8471-99fd3411ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the face encodings\n",
    "face_encodings = face_recognition.face_encodings(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30973c3d-4738-4d9e-981e-87defcce56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20855837  0.01845226  0.05200073 -0.01912922 -0.02748854 -0.01855117\n",
      " -0.027255   -0.01845023  0.19835591 -0.01124563  0.19645655  0.01600665\n",
      " -0.15621799 -0.08862405 -0.00915151  0.11604425 -0.12597199 -0.14229293\n",
      " -0.03572801 -0.03505832  0.03726116  0.03980891 -0.07782653  0.07926028\n",
      " -0.14744216 -0.34706149 -0.10856137 -0.12216783  0.01723715 -0.11650674\n",
      "  0.06511289 -0.03900207 -0.18297048 -0.10930699  0.06847547  0.12637658\n",
      " -0.05037975 -0.09572256  0.13429828 -0.00703454 -0.16005868 -0.0557308\n",
      "  0.08435319  0.27441856  0.13435347  0.08523711  0.00496125 -0.11246422\n",
      "  0.16313241 -0.27373853  0.08402456  0.10128957  0.15344822  0.108321\n",
      "  0.11609212 -0.09201837  0.07474779  0.254884   -0.30816704  0.10207555\n",
      "  0.00198605 -0.01495524  0.03411678 -0.02620059  0.21705669  0.14441353\n",
      " -0.11093335 -0.12751675  0.17208098 -0.16183105 -0.04968167  0.12839431\n",
      " -0.03207513 -0.26411179 -0.31615093  0.07128873  0.36264002  0.18028145\n",
      " -0.13117109 -0.01013268 -0.05811105 -0.00737815  0.03560945  0.03457598\n",
      " -0.09948459 -0.06623539 -0.05779984 -0.01711861  0.24389154  0.12510221\n",
      "  0.003106    0.16942374 -0.01417198 -0.02782673  0.001431    0.06574464\n",
      " -0.10071306  0.00664665 -0.07640257 -0.06614345  0.03114731  0.03002048\n",
      "  0.07674068  0.13323891 -0.21063036  0.15302028 -0.0154896  -0.04833602\n",
      "  0.00523049 -0.02149037 -0.06463669  0.01915049  0.14195821 -0.29341784\n",
      "  0.22209316  0.12297856  0.04837456  0.15621082  0.00215635  0.00968098\n",
      " -0.03717988 -0.1172902  -0.17494754 -0.01424954  0.05999131 -0.07590403\n",
      "  0.0759552  -0.00694486]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings) == 0:\n",
    "    # No faces found in the image.\n",
    "    print(\"No faces were found.\")\n",
    "\n",
    "else:\n",
    "    # Grab the first face encoding\n",
    "    first_face_encoding = face_encodings[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(first_face_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0fbba-8b82-4522-bddd-f5f31df0287e",
   "metadata": {},
   "source": [
    "## Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7de1acf-c57d-4de8-be92-7047f112797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e160ff-2e5e-4456-a5e5-b4ffa4444326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the known images\n",
    "image_of_person_1 = face_recognition.load_image_file(\"./06/person_1.jpg\")\n",
    "image_of_person_2 = face_recognition.load_image_file(\"./06/person_2.jpg\")\n",
    "image_of_person_3 = face_recognition.load_image_file(\"./06/person_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf99cf5f-487a-4538-a56f-5a429ced0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the face encoding of each person. This can fail if no one is found in the photo.\n",
    "person_1_face_encoding = face_recognition.face_encodings(image_of_person_1)[0]\n",
    "person_2_face_encoding = face_recognition.face_encodings(image_of_person_2)[0]\n",
    "person_3_face_encoding = face_recognition.face_encodings(image_of_person_3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f465105-f4ea-459b-86ed-7e9303cd0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all known face encodings\n",
    "known_face_encodings = [\n",
    "    person_1_face_encoding,\n",
    "    person_2_face_encoding,\n",
    "    person_3_face_encoding\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3303bc4e-62f4-4783-8790-201b02844949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image we want to check\n",
    "unknown_image = face_recognition.load_image_file(\"./06/unknown_7.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0097c734-97c4-486e-b186-30051f40f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get face encodings for any people in the picture\n",
    "face_locations = face_recognition.face_locations(unknown_image, number_of_times_to_upsample = 2)\n",
    "unknown_face_encodings = face_recognition.face_encodings(unknown_image, known_face_locations = face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73a0a7ca-4216-43b6-b0b9-b393c2054c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Person 2 in the photo!\n"
     ]
    }
   ],
   "source": [
    "# There might be more than one person in the photo, so we need to loop over each face we found\n",
    "for unknown_face_encoding in unknown_face_encodings:\n",
    "\n",
    "    # Test if this unknown face encoding matches any of the three people we know\n",
    "    results = face_recognition.compare_faces(known_face_encodings, unknown_face_encoding)\n",
    "\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    if results[0]:\n",
    "        name = \"Person 1\"\n",
    "    elif results[1]:\n",
    "        name = \"Person 2\"\n",
    "    elif results[2]:\n",
    "        name = \"Person 3\"\n",
    "\n",
    "    print(f\"Found {name} in the photo!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33398d-d6a4-498b-ab39-c86be8f2acb4",
   "metadata": {},
   "source": [
    "## Uses of Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824740f7-80dd-472b-ae12-52145a33afb4",
   "metadata": {},
   "source": [
    "## Makeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f20acd70-a56c-470f-8240-252a357282f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3eb4395a-27c9-4f04-97df-69aeb0381d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"./07/people.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b142b11b-5769-4cf4-b7a0-e24db4d3d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81e2137f-1944-4061-b437-fb4f572ceddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image into a Python Image Library object so that we can draw on top of it and display it\n",
    "pil_image = Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab838b38-1ecc-4162-becc-af26653032f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PIL drawing object to be able to draw lines later\n",
    "d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "    # The face landmark detection model returns these features:\n",
    "    #  - chin, left_eyebrow, right_eyebrow, nose_bridge, nose_tip, left_eye, right_eye, top_lip, bottom_lip\n",
    "   \n",
    "    # Draw a line over the eyebrows\n",
    "    d.line(face_landmarks[\"left_eyebrow\"], fill=(128,0,128,100), width = 3)\n",
    "    d.line(face_landmarks[\"right_eyebrow\"], fill=(128,0,128,100), width = 3)\n",
    "    \n",
    "    \n",
    "    # Draw over the lips\n",
    "    d.polygon(face_landmarks[\"top_lip\"], fill=(128,0,128,100))\n",
    "    d.polygon(face_landmarks[\"bottom_lip\"], fill=(128,0,128,100))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc31b2f6-7a93-41ba-9550-0eb684f7a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final image\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03acc85-35aa-4320-b33d-ecea0a5b2266",
   "metadata": {},
   "source": [
    "## Lookalikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a9ae5bb-78fc-4d27-9fbf-9e8dacce9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e31e57b-2fc2-494a-8f9e-c8e353e88745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image of the person we want to find similar people for\n",
    "known_image = face_recognition.load_image_file(\"./07/test_face.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4bc72343-3be5-4d93-b5a9-2e94f2162a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the known image\n",
    "known_image_encoding = face_recognition.face_encodings(known_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73917bc8-9ebe-493a-97cf-f7bd86ef8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to keep track of the most similar face match we've found\n",
    "best_face_distance = 1.0\n",
    "best_face_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fac66f44-9c4e-458c-b7b1-0b85613e6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the images we want to check for similar people\n",
    "for image_path in Path(\"./07/people\").glob(\"*.png\"):\n",
    "    # Load an image to check\n",
    "    unknown_image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "    # Get the location of faces and face encodings for the current image\n",
    "    face_encodings = face_recognition.face_encodings(unknown_image)\n",
    "\n",
    "    # Get the face distance between the known person and all the faces in this image\n",
    "    face_distance = face_recognition.face_distance(face_encodings, known_image_encoding)[0]\n",
    "\n",
    "    # If this face is more similar to our known image than we've seen so far, save it\n",
    "    if face_distance < best_face_distance:\n",
    "        # Save the new best face distance\n",
    "        best_face_distance = face_distance\n",
    "        # Extract a copy of the actual face image itself so we can display it\n",
    "        best_face_image = unknown_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b44da669-e55e-4c23-9378-f0e8b9b2d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the face image that we found to be the best match!\n",
    "pil_image = Image.fromarray(best_face_image)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2916dc-c9ed-4617-a42d-7ad4d8a6e684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92685aaf-1863-4ab0-9895-7ba33a71cec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
